import pandas as pd
import numpy as np

"""
    2ï¸âƒ£ transform.py â€” Pure Data Transformation Layer
    ğŸ“Œ ì—­í• 
        DataFrame â†’ DataFrame ë³€í™˜
        ë°ì´í„° í˜•íƒœÂ·êµ¬ì¡°Â·ì§€í‘œ ê³„ì‚°

    ğŸ“¦ í¬í•¨ í•¨ìˆ˜
        * add_ma
        * filter_ohlcv
        * filter_finance_history
        * slice_ohlcv
        * add_returns
        * add_interval_returns
        * align_dfs_by_date_intersection
        * merge_dfs_to_df
        * drop_columns
        * add_avg_score
        * select_rows_by_interval_with_ends
"""

def add_ma(
    dfs:dict,
    windows=(5,10,20,60,120),
    price_col="Close",
    prefix="MA"
) ->dict:

    """
    ì´í‰ì„  êµ¬í•˜ê¸°
    dfs: { 'AAPL': df, 'MSFT': df, ... }
    windows: ì´ë™í‰ê·  ê¸°ê°„ë“¤ (int ë˜ëŠ” iterable)
    price_col: ê¸°ì¤€ ê°€ê²© ì»¬ëŸ¼ (ë³´í†µ Close)
    prefix: ì»¬ëŸ¼ëª… ì ‘ë‘ì‚¬ (MA5, MA20 ...)
    """
    # windowsê°€ ë‹¨ì¼ ì •ìˆ˜ë©´ íŠœí”Œë¡œ ë³€í™˜
    if isinstance(windows, int):
        windows = (windows,)
    
    out = {}

    for t, df in dfs.items():
        d = df.copy()

        # ì•ˆì „ì¥ì¹˜: ì •ë ¬ + íƒ€ì…
        d["Date"] = pd.to_datetime(d["Date"])
        d = d.sort_values("Date")

        # ì´ë™í‰ê·  ìƒì„±
        for w in windows:
            d[f"{prefix}{w}"] = d[price_col].rolling(window=w, min_periods=w).mean()

        # ê°€ì¥ ê¸´ ì´ë™í‰ê· ì„  ê°’ì´ Nanì´ë©´ ì œì™¸í•˜ì
        d = d.dropna(subset=[f"{prefix}{max(windows)}"])
        out[t] = d

    return out


def filter_ohlcv(dfs: dict, option: str) -> dict:
    """
    OHLCV í•„í„°ë§

    option
        - "month_end" : ë§¤ì›”ë§(ì‹¤ì œ ë§ˆì§€ë§‰ ê±°ë˜ì¼)
        - "year_end"  : ë§¤ë…„ë§(ì‹¤ì œ ë§ˆì§€ë§‰ ê±°ë˜ì¼)
    """

    out = {}

    for key, df in dfs.items():
        d = filter_finance_history(df, option)
        out[key] = d

    return out


def filter_finance_history(df: pd.DataFrame, option: str) -> pd.DataFrame:
    """
    ê¸ˆìœµ ë°ì´í„° í•„í„°ë§

    option
        - "month_start" : ë§¤ì›”ì´ˆ(ì‹¤ì œ ì²« ê±°ë˜ì¼)
        - "month_end"   : ë§¤ì›”ë§(ì‹¤ì œ ë§ˆì§€ë§‰ ê±°ë˜ì¼)
        - "year_start"  : ë§¤ë…„ì´ˆ(ì‹¤ì œ ì²« ê±°ë˜ì¼)
        - "year_end"    : ë§¤ë…„ë§(ì‹¤ì œ ë§ˆì§€ë§‰ ê±°ë˜ì¼)
    """
    d = df.copy()
    d["Date"] = pd.to_datetime(d["Date"])
    d = d.sort_values("Date").set_index("Date")

    if option == "month_start":
        freq = "BMS"
        selector = "head"
    elif option == "month_end":
        freq = "BME"
        selector = "tail"
    elif option == "year_start":
        freq = "BYS"
        selector = "head"
    elif option == "year_end":
        freq = "BYE"
        selector = "tail"
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” optionì…ë‹ˆë‹¤: {option}")

    # 1ï¸âƒ£ ê¸°ê°„ë³„ ë°°ë‹¹ê¸ˆ í•©ê³„
    dividends_sum = (
        d["Dividends"]
        .groupby(pd.Grouper(freq=freq))
        .sum()
    )

    # 2ï¸âƒ£ ê¸°ê°„ë³„ ì²«/ë§ˆì§€ë§‰ ê±°ë˜ì¼
    grouped = d.groupby(pd.Grouper(freq=freq))
    result = grouped.head(1) if selector == "head" else grouped.tail(1)

    # 3ï¸âƒ£ ë°°ë‹¹ê¸ˆ í•©ê³„ ë°˜ì˜
    result["Dividends"] = dividends_sum.values

    return result.reset_index()



def slice_ohlcv(dfs: dict, start=None, end=None) -> dict:
    """
    OHLCV dictì—ì„œ Date ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì • ê¸°ê°„ë§Œ ìŠ¬ë¼ì´ì‹±

    start : str | datetime | None
        ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
    end : str | datetime | None
        ì¢…ë£Œ ë‚ ì§œ (Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ)
    """

    # endê°€ Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
    if end is None:
        end = pd.Timestamp.today().normalize()
    else:
        end = pd.to_datetime(end)

    # startëŠ” Noneì´ë©´ ê·¸ëŒ€ë¡œ ë‘ 
    if start is not None:
        start = pd.to_datetime(start)

    out = {}

    for ticker, df in dfs.items():
        d = df.copy()

        d["Date"] = pd.to_datetime(d["Date"])
        d = d.sort_values("Date")

        # start / end ì˜ˆì™¸ ì²˜ë¦¬
        if start is not None:
            d = d[d["Date"] >= start]

        d = d[d["Date"] <= end]

        out[ticker] = d.reset_index(drop=True)

    return out


def add_returns(
    dfs_by_ticker: dict,
    price_col: str = "Close",
    out_col: str = "Return",
    method: str = "simple",   # "simple" or "log"
    fill_first: float | None = np.nan
) -> dict:
    """
    ê° í‹°ì»¤ë³„ OHLCV DataFrameì— ì „ row ëŒ€ë¹„ ìˆ˜ìµë¥  ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ ë°˜í™˜.

    Parameters
    ----------
    dfs_by_ticker : dict
        { 'AAPL': df, 'MSFT': df, ... }
    price_col : str
        ìˆ˜ìµë¥  ê³„ì‚°ì— ì‚¬ìš©í•  ê°€ê²© ì»¬ëŸ¼ (ë³´í†µ Close)
    out_col : str
        ê²°ê³¼ ìˆ˜ìµë¥  ì»¬ëŸ¼ëª…
    method : str
        "simple" : (P_t / P_{t-1}) - 1
        "log"    : log(P_t / P_{t-1})
    fill_first : float | None
        ì²« í–‰ ìˆ˜ìµë¥ (ì´ì „ê°’ì´ ì—†ì–´ NaN) ì²˜ë¦¬ê°’.
        Noneì´ë©´ ê·¸ëŒ€ë¡œ ë‘ , ê¸°ë³¸ì€ NaN.

    Returns
    -------
    dict
        ìˆ˜ìµë¥  ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame dict
    """
    out = {}

    for t, df in dfs_by_ticker.items():
        d = df.copy()

        # ì•ˆì „: ë‚ ì§œ ì •ë ¬
        if "Date" in d.columns:
            d["Date"] = pd.to_datetime(d["Date"])
            d = d.sort_values("Date")

        # ê°€ê²© ì»¬ëŸ¼ ì²´í¬
        if price_col not in d.columns:
            raise KeyError(f"[{t}] '{price_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(d.columns)}")

        s = d[price_col].astype(float)

        if method == "simple":
            r = s.pct_change()
        elif method == "log":
            r = np.log(s).diff()
        else:
            raise ValueError("methodëŠ” 'simple' ë˜ëŠ” 'log'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        if fill_first is not None:
            r = r.fillna(fill_first)

        d[out_col] = r
        out[t] = d.reset_index(drop=True)

    return out


def add_interval_returns(
    dfs: dict,
    return_intervals: list,
    price_col: str = "Close",
    date_col: str = "Date",
    suffix: str = "MReturn"
) -> dict:
    """
    dfs(dict)ì˜ ê° DataFrameì— Nê°œì›” ëˆ„ì  ìˆ˜ìµë¥  ì»¬ëŸ¼ ì¶”ê°€

    ì˜ˆ:
        return_intervals = [1, 3, 6]
        â†’ 1MReturn, 3MReturn, 6MReturn

    ìˆ˜ìµë¥  ì •ì˜:
        (P_t / P_{t-n}) - 1
    """

    out = {}

    for key, df in dfs.items():
        d = df.copy()

        # ì•ˆì „ ì²˜ë¦¬
        d[date_col] = pd.to_datetime(d[date_col])
        d = d.sort_values(date_col).reset_index(drop=True)

        if price_col not in d.columns:
            raise KeyError(f"[{key}] '{price_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        price = d[price_col].astype(float)

        for n in return_intervals:
            col_name = f"{n}{suffix}"
            d[col_name] = price / price.shift(n) - 1

        # ê°€ì¥ ê¸´ ì´ë™í‰ê· ì„  ê°’ì´ Nanì´ë©´ ì œì™¸í•˜ì
        d = d.dropna(subset=[f"{max(return_intervals)}{suffix}"])
        out[key] = d

    return out


def align_dfs_by_date_intersection(
    dfs: dict,
    date_col: str = "Date"
) -> dict:
    """
    dfs(dict)ì˜ ê° DataFrameì„ Date ì»¬ëŸ¼ ê¸°ì¤€ êµì§‘í•©ìœ¼ë¡œ ì •ë ¬

    Parameters
    ----------
    dfs : dict
        { 'AAPL': df, 'MSFT': df, ... }
    date_col : str
        ë‚ ì§œ ì»¬ëŸ¼ëª… (ê¸°ë³¸: "Date")

    Returns
    -------
    dict
        Date êµì§‘í•©ë§Œ ë‚¨ê¸´ DataFrame dict
    """

    if not dfs:
        return {}

    # 1ï¸âƒ£ ëª¨ë“  dfì˜ Dateë¥¼ setìœ¼ë¡œ ìˆ˜ì§‘
    date_sets = []

    for df in dfs.values():
        if date_col not in df.columns:
            raise KeyError(f"'{date_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        s = pd.to_datetime(df[date_col]).dropna().unique()
        date_sets.append(set(s))

    # 2ï¸âƒ£ Date êµì§‘í•©
    common_dates = set.intersection(*date_sets)

    if not common_dates:
        raise ValueError("ê³µí†µ Dateê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 3ï¸âƒ£ ê° df í•„í„°ë§
    out = {}

    for key, df in dfs.items():
        d = df.copy()
        d[date_col] = pd.to_datetime(d[date_col])

        d = (
            d[d[date_col].isin(common_dates)]
              .sort_values(date_col)
              .reset_index(drop=True)
        )

        out[key] = d

    return out


def merge_dfs_to_df(dfs: dict, input_df: pd.DataFrame) -> dict:
    """
    dfs ë”•ì…”ë„ˆë¦¬ì˜ ê° dfì— input_dfë¥¼ ë³‘í•©í•˜ê¸°
    ex. í™˜ìœ¨ ê°™ì€ ë°ì´í„° ê° ì—´ì— ì¶”ê°€í•  ë•Œ ì‚¬ìš©
    """

    def normalize_date(df, col="Date"):
        d = df.copy()
        d[col] = pd.to_datetime(d[col])

        # timezone ìˆìœ¼ë©´ ì œê±°
        if d[col].dt.tz is not None:
            d[col] = d[col].dt.tz_localize(None)

        return d

    # input_df ì •ë¦¬
    idf = normalize_date(input_df)
    idf = idf.sort_values("Date")

    out = {}

    for key, df in dfs.items():
        d = normalize_date(df)
        d = d.sort_values("Date")

        d = pd.merge(
            d,
            idf,
            on="Date",
            how="left"
        )

        out[key] = d

    return out


def drop_columns(dfs:dict, drop_cols) -> dict:
    """
        íŠ¹ì • ì»¬ëŸ¼ ì œê±°
    """
    
    if isinstance(drop_cols, str):
        drop_cols = [drop_cols]
    
    out ={}
    
    for key, df in dfs.items():
        d = df.copy()
        d = d.drop(columns=drop_cols)

        out[key] =d

    return out


def add_avg_score(
    dfs:dict,
    return_cols = ("1MReturn", "3MReturn", "6MReturn", "12MReturn"),
    out_col ="Avg Score",
) -> dict:

    out = {}
    for key, df in dfs.items():
        d = df.copy()

        missing = [c for c in return_cols if c not in d.columns]
        if missing:
            raise KeyError(f"ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ : {missing}")

        d[out_col] = d[list(return_cols)].mean(axis=1)
        out[key] = d

    return out


def select_rows_by_interval_with_ends(
    dfs:dict,
    interval:int
)-> dict:
    """
    interval ê°„ê²©ìœ¼ë¡œ row ì„ íƒí•˜ë˜,
    ì²« rowì™€ ë§ˆì§€ë§‰ rowëŠ” ë°˜ë“œì‹œ í¬í•¨
    """
    if interval <= 0:
        raise ValueError("intervalì€ 1ì´ìƒì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    out = {}
    for key, df in dfs.items():
        d = df.copy()

        n = len(df)
        if n == 0:
            out[key] = d
            continue

        idx = list(range(0, n, interval))
        
        if (n-1) not in idx:
            idx.append(n-1)

        d = d.iloc[idx].reset_index(drop=True)
        out[key] = d

    return out